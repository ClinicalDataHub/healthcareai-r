% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/evaluate.R
\name{evaluate}
\alias{evaluate}
\title{Get performance metrics from predictions data frame}
\usage{
evaluate(d)
}
\arguments{
\item{d}{Data frame from \code{\link{predict.model_list}} containing realized
outcomes}
}
\value{
Vector of scores with metrics as names
}
\description{
Get performance metrics from predictions data frame
}
\details{
This function is designed to work with predictions coming from
  \code{\link{machine_learn}} / \code{\link{tune_models}} /
  \code{\link{flash_models}} through \code{\link{predict.model_list}}. The
  data passed to \code{predict} must contain observed outcomes. If you have
  predictions and outcomes in a different format, use
  \code{\link{evaluate_classification}} or \code{\link{evaluate_regression}}.
}
\examples{
models <- machine_learn(pima_diabetes[1:40, ], patient_id, outcome = diabetes,
                        models = "rf", tune_depth = 3)
predictions <- predict(models, newdata = pima_diabetes[41:50, ])
evaluate(predictions)
}
