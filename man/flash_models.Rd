% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/flash_models.R
\name{flash_models}
\alias{flash_models}
\title{Train models without tuning for performance}
\usage{
flash_models(d, outcome, models = c("rf", "knn"), metric, positive_class,
  n_folds = 5, hyperparameters, model_class)
}
\arguments{
\item{d}{A data frame}

\item{outcome}{Name of the column to predict}

\item{models}{Names of models to try, by default "rf" for random forest and
"knn" for k-nearest neighbors. See \code{\link{supported_models}} for
available models.}

\item{metric}{What metric to use to assess model performance? Options for
regression: "RMSE" (root-mean-squared error, default), "MAE" (mean-absolute
error), or "Rsquared." For classification: "ROC" (area under the receiver
operating characteristic curve), or "PR" (area under the precision-recall
curve).}

\item{positive_class}{For classification only, which outcome level is the
"yes" case, i.e. should be associated with high probabilities? Defaults to
"Y" or "yes" if present, otherwise is the first level of the outcome
variable (first alphabetically if the training data outcome was not already
a factor).}

\item{n_folds}{How many folds to train the model on. Default = 5, minimum =
2. Whie flash_models doesn't use cross validation to tune hyperparameters,
it trains \code{n_folds} models to evaluate performance out of fold.}

\item{hyperparameters}{Optional list of hyperparameters to use. If missing,
default values will be used. If provided, must be a named list of named
lists where the outer list contains models and the inner lists contain
hyperparameter values. See
\code{healthcareai:::get_hyperparameter_defaults()} for a template.}

\item{model_class}{"regression" or "classification". If not provided, this
will be determined by the class of `outcome` with the determination
displayed in a message.}
}
\value{
A model_list object
}
\description{
Train models without tuning for performance
}
\details{
This function has two major differences from
  \code{\link{tune_models}}: 1. It uses fixed hyperparameter values to train
  models instead of using cross-validation to optimize hyperparameter values
  for predictive performance, and, as a result, 2. It is much faster.
}
\examples{
\dontrun{
# Prepare data
prepped_data <- prep_data(pima_diabetes, patient_id, outcome = diabetes)

# Simplest use. Get models quickly at default hyperparameter values
flash_models(prepped_data, diabetes)

# Set non-default hyperparameter values by passing a list of lists to \\code{hyperparameters}
models <-
  flash_models(d = prepped_data,
               outcome = diabetes,
               hyperparameters = list(
                 rf = list(
                   mtry = 3,
                   splitrule = "gini",
                   min.node.size = 1
                 ),
                 knn = list(
                   kmax = 3,
                   distance = 2,
                   kernel = "gaussian"
                 )
               )
  )
summary(models)

# Speed comparison of no tuning with flash_models vs. tuning with tune_models:
# ~40 seconds:
system.time(
  tune_models(prepped_data, diabetes)
)
# ~6 seconds:
system.time(
  flash_models(prepped_data, diabetes)
)
}
}
\seealso{
\code{\link{tune_models}}, \code{\link{prep_data}},
  \code{\link{predict.model_list}}, \code{\link{supported_models}}
}
